{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade\n",
    "\n",
    "# install joblib. This is used to save the model. \n",
    "# # Restart your kernel after installing \n",
    "# !pip install joblib\n",
    "\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv into a dataframe\n",
    "data_read = pd.read_csv(\"../Resources/fraudTrain.csv\")\n",
    "data_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_read.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraud/non-fraud transaction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read['is_fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the fraud/non-fraud transaction distribution\n",
    "\n",
    "fig = sns.catplot('is_fraud', data=data_read, kind='count', height=4.5, aspect=1)\n",
    "plt.title(\"Fraud vs Non-Fraud Transaction Distribution\\n\")\n",
    "plt.savefig(\"../static/images/distribution.jpg\", bbox_inches='tight')\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xlabel(\"Status\")\n",
    "fig.set_xticklabels(['Non-fraud', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced with 1289169 legitimate transactions and 7506 fraud transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_notfraud = data_read[data_read.is_fraud==0]\n",
    "data_fraud = data_read[data_read.is_fraud==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_notfraud.shape, data_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_notfraud['amt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fraud['amt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the data\n",
    "\n",
    "### Up Sampling minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate majority and minority classes\n",
    "df_majority = data_read[data_read.is_fraud==0]\n",
    "df_minority = data_read[data_read.is_fraud==1]\n",
    "print(df_majority.size)\n",
    "print(df_minority.size)\n",
    "data_read.is_fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "# nsamples = df_majority.is_fraud.count()\n",
    "\n",
    "nsamples = round(df_majority.is_fraud.count()/2).astype(int)\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=nsamples,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled.is_fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled.is_fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the distribtution with the balanced dataset\n",
    "fig = sns.catplot('is_fraud', data=df_upsampled, kind='count', height=4.5, aspect=1)\n",
    "plt.title(\"Fraud vs Non-Fraud Transaction Distribution\\n(Balanced Data)\")\n",
    "plt.savefig(\"../static/images/distribution_balanced.jpg\", bbox_inches='tight')\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xlabel(\"Status\")\n",
    "fig.set_xticklabels(['Non-fraud', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "f.suptitle('Amount per transaction by class')\n",
    "bins = 50\n",
    "ax1.hist(data_fraud.amt, bins = bins)\n",
    "ax1.set_title('Fraud')\n",
    "ax2.hist(data_notfraud.amt, bins = bins)\n",
    "ax2.set_title('Not Fraud')\n",
    "\n",
    "plt.xlabel('Amount ($)')\n",
    "f.text(.01, .5, 'Number of transactions', ha='center', va='center', rotation='vertical')\n",
    "plt.xlim((0, 20000))\n",
    "plt.yscale('log')\n",
    "plt.savefig(\"../static/images/histogram_balanced.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "f.suptitle('Amount per transaction by time')\n",
    "ax1.scatter(data_fraud.category, data_fraud.amt)\n",
    "ax1.set_title('Fraud')\n",
    "ax2.scatter(data_notfraud.category, data_notfraud.amt)\n",
    "ax2.set_title('Not Fraud')\n",
    "plt.xlabel('Category', fontsize=11)\n",
    "plt.xticks(rotation=45)\n",
    "f.text(.01, .5, 'Transaction Amount', ha='center', va='center', rotation='vertical')\n",
    "plt.savefig(\"../static/images/category-plot.jpg\",  bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "f.suptitle('Amount per transaction by time')\n",
    "\n",
    "ax1.scatter(data_fraud.trans_date_trans_time, data_fraud.amt)\n",
    "ax1.set_title('Fraud')\n",
    "ax2.scatter(data_notfraud.trans_date_trans_time, data_notfraud.amt)\n",
    "ax2.set_title('Not Fraud')\n",
    "plt.xlabel('Time', fontsize=11)\n",
    "f.text(.01, .5, 'Transaction Amount', ha='center', va='center', rotation='vertical')\n",
    "plt.xticks(rotation=45)\n",
    "# plt.ylabel('Amount')\n",
    "plt.figure(figsize=(4, 10))\n",
    "plt.savefig(\"../static/images/unixtime-plot.jpg\",  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data_read.sample(frac=0.1, random_state=1)\n",
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "Convert categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date of birth into numeric as age\n",
    "data_train = df_upsampled\n",
    "data_train['dob']= pd.to_datetime(data_train['dob'])\n",
    "data_train['dob']\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "data_train['age'] = round(data_train['dob'].apply(lambda x: (today - x).days//365.25),0)\n",
    "data_train['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe column names\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns which are required for the further processing\n",
    "data_train = data_train[[\"category\", \"cc_num\", \"amt\", \"lat\",\"long\", \"job\", \"age\", \"trans_num\", \n",
    "                         \"unix_time\", \"merch_lat\",\"merch_long\", \"is_fraud\"]]\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the transaction number and convert into numeric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "get_transnum = data_train['trans_num']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(get_transnum)\n",
    "encoded_transnum = label_encoder.transform(get_transnum)\n",
    "data_train['trans_num'] = encoded_transnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the category and convert into numeric\n",
    "get_category = data_train['category']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(get_category)\n",
    "encoded_category = label_encoder.transform(get_category)\n",
    "data_train['category'] = encoded_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the job and convert into numeric\n",
    "get_job = data_train['job']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(get_job)\n",
    "encoded_job = label_encoder.transform(get_job)\n",
    "data_train['job'] = encoded_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets y to is_fraud\n",
    "target = data_train[\"is_fraud\"].values.reshape(-1, 1)\n",
    "\n",
    "# Define the features\n",
    "selected_features = data_train.drop('is_fraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependecnies\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the selected dataset into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the train & test datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a standard scaler model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform the scaled data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Random Forest Classifier Model to get the feature importance/weightage\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the random forest model to X and y\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Return the importance of each column to predicting the outcomes\n",
    "importances = rf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each column in order of importance\n",
    "rf_weights = sorted(zip(importances, selected_features.keys()), reverse=True)\n",
    "rf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the weighted feature list into a dataframe\n",
    "rf_weighted_df = pd.DataFrame(rf_weights)\n",
    "rf_weighted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe into a csv file for plotting\n",
    "rf_weighted_df.to_csv(\"../exporteddata/random_forest_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the random forest features\n",
    "\n",
    "colors = ['#c6dbef','#9ecae1','#9ecae1','#9ecae1','#6baed6','#6baed6','#4292c6','#2171b5','#2171b5','#08519c','#08306b','#023858']\n",
    "sorted_idx = importances.argsort()\n",
    "# plt.barh(selected_features.columns[sorted_idx], importances[sorted_idx], color=['#FFFFCC',#D9F0A3','#ADDD8E','#78C679','#31A354','#006837'])\n",
    "plt.barh(selected_features.columns[sorted_idx], importances[sorted_idx], color=colors)\n",
    "\n",
    "plt.title(\"RandomForest feature importance on the outcome\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.savefig(\"../static/images/randomforest_balanced.jpg\",  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(n_estimators=20)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_weights = sorted(zip(xgb.feature_importances_, selected_features.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df = pd.DataFrame(xgb_weights)\n",
    "xgb_df.to_csv(\"../exporteddata/xgboost_features_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = xgb.feature_importances_.argsort()\n",
    "plt.barh(selected_features.columns[sorted_idx], xgb.feature_importances_[sorted_idx])\n",
    "plt.title(\"XGBoost feature importance\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.savefig(\"../static/images/xgb_balanced.jpg\", bbox_inches='tight')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def correlation_heatmap(train):\n",
    "    correlations = train.corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f', cmap=\"YlGnBu\",\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70}\n",
    "                )\n",
    "    plt.title(\"Feature correlation diagram\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.savefig(\"../static/images/correlation_balanced.jpg\", bbox_inches='tight')\n",
    "    plt.show();\n",
    "\n",
    "correlation_heatmap(X_train[selected_features.columns[sorted_idx]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
